

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>vectorhub.bi_encoders.text_image.torch package &mdash; VectorHub 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> VectorHub
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro.html">What is Vector Hub?</a></li>
<li class="toctree-l1"><a class="reference internal" href="how_to_add_a_model.html">How To Add Your Model To Vector Hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_encoder.html">Guide to using Auto-Encoder</a></li>
</ul>
<p class="caption"><span class="caption-text">Text Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.bert2vec.html">Bert2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.albert2vec.html">AlBert2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.labse2vec.html">LaBSE2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.use2vec.html">USE2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.use_multi2vec.html">USEMulti2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.legalbert2vec.html">LegalBert2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.transformer2vec.html">Transformer2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.sentencetransformer2vec.html">SentenceTransformer2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.text.vectorai2vec.html">ViText2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Image Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.bit2vec.html">Bit2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.inception2vec.html">Inception2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.resnet2vec.html">ResNet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.inception_resnet2vec.html">InceptionResnet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.mobilenet2vec.html">MobileNet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.image.vectorai2vec.html">ViImage2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Audio Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.speech_embedding2vec.html">SpeechEmbedding2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.trill2vec.html">Trill2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.vggish2vec.html">Vggish2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.yamnet2vec.html">Yamnet2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.wav2vec.html">Wav2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoders.audio.vectorai2vec.html">ViAudio2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Text Bi-Encoders</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bi_encoders.text_text.use_qa2vec.html">USEQA2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="bi_encoders.text_text.lareqa_qa2vec.html">LAReQA2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="bi_encoders.text_text.dpr2vec.html">DPR2Vec</a></li>
</ul>
<p class="caption"><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">vectorhub</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">VectorHub</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>vectorhub.bi_encoders.text_image.torch package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/vectorhub.bi_encoders.text_image.torch.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="vectorhub-bi-encoders-text-image-torch-package">
<h1>vectorhub.bi_encoders.text_image.torch package<a class="headerlink" href="#vectorhub-bi-encoders-text-image-torch-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-vectorhub.bi_encoders.text_image.torch.clip2vec">
<span id="vectorhub-bi-encoders-text-image-torch-clip2vec-module"></span><h2>vectorhub.bi_encoders.text_image.torch.clip2vec module<a class="headerlink" href="#module-vectorhub.bi_encoders.text_image.torch.clip2vec" title="Permalink to this headline">¶</a></h2>
<p><strong>Model Name</strong>: CLIP</p>
<p><strong>Vector Length</strong>: 512 (default)</p>
<p><strong>Description</strong>:</p>
<p><strong>Paper</strong>: <a class="reference external" href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf">https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf</a>)</p>
<p><strong>Repository</strong>:</p>
<p><strong>Architecture</strong>: Not stated.</p>
<p><strong>Tasks</strong>: Not stated.</p>
<p><strong>Release Date</strong>: 2021-01-01</p>
<p><strong>Limitations</strong>:
CLIP and our analysis of it have a number of limitations. CLIP currently struggles with respect to certain tasks such as fine grained classification and counting objects. CLIP also poses issues with regards to fairness and bias which we discuss in the paper and briefly in the next section. Additionally, our approach to testing CLIP also has an important limitation- in many cases we have used linear probes to evaluate the performance of CLIP and there is evidence suggesting that linear probes can underestimate model performance.</p>
<p><strong>Installation</strong>: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">vectorhub[clip]</span></code></p>
<p><strong>Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">#pip</span> <span class="pre">install</span> <span class="pre">vectorhub[clip]</span>
<span class="pre">from</span> <span class="pre">vectorhub.bi_encoders.text_image.torch</span> <span class="pre">import</span> <span class="pre">Clip2Vec</span>
<span class="pre">model</span> <span class="pre">=</span> <span class="pre">Clip2Vec()</span>
<span class="pre">model.encode_image(image_url)</span>
<span class="pre">model.encode_text(text)</span>
<span class="pre">`</span></code></p>
<p>Inspired by [Model Cards for Model Reporting (Mitchell et al.)](<a class="reference external" href="https://arxiv.org/abs/1810.03993">https://arxiv.org/abs/1810.03993</a>) and [Lessons from Archives (Jo &amp; Gebru)](<a class="reference external" href="https://arxiv.org/pdf/1912.10389.pdf">https://arxiv.org/pdf/1912.10389.pdf</a>), we’re providing some accompanying information about the multimodal model.</p>
<dl class="py class">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec">
<em class="property">class </em><code class="sig-prename descclassname">vectorhub.bi_encoders.text_image.torch.clip2vec.</code><code class="sig-name descname">Clip2Vec</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">url</span><span class="o">=</span><span class="default_value">'ViT-B/32'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="vectorhub.encoders.image.html#vectorhub.encoders.image.base.BaseImage2Vec" title="vectorhub.encoders.image.base.BaseImage2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">vectorhub.encoders.image.base.BaseImage2Vec</span></code></a>, <a class="reference internal" href="vectorhub.encoders.text.html#vectorhub.encoders.text.base.BaseText2Vec" title="vectorhub.encoders.text.base.BaseText2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">vectorhub.encoders.text.base.BaseText2Vec</span></code></a></p>
<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.add_documents">
<code class="sig-name descname">add_documents</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">username</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">api_key</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">items</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Any<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">metadata</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>Any<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">collection_name</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.add_documents" title="Permalink to this definition">¶</a></dt>
<dd><p>Add documents to the Vector AI cloud.</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.bulk_encode">
<code class="sig-name descname">bulk_encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">data_type</span><span class="o">=</span><span class="default_value">'image'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.bulk_encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.bulk_encode_image">
<code class="sig-name descname">bulk_encode_image</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">images</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.bulk_encode_image" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.bulk_encode_text">
<code class="sig-name descname">bulk_encode_text</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">texts</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.bulk_encode_text" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.chunk">
<em class="property">classmethod </em><code class="sig-name descname">chunk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lst</span><span class="p">:</span> <span class="n">List</span></em>, <em class="sig-param"><span class="n">chunk_size</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.chunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Chunk an iterable object in Python but not a pandas DataFrame.
:param lst: Python List
:param chunk_size: The chunk size of an object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">documents</span> <span class="o">=</span> <span class="p">[{</span><span class="o">...</span><span class="p">}]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ViClient</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.definition">
<code class="sig-name descname">definition</code><em class="property"> = &lt;vectorhub.doc_utils.ModelDefinition object&gt;</em><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.definition" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.delete_collection">
<code class="sig-name descname">delete_collection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">collection_name</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.delete_collection" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">data_type</span><span class="o">=</span><span class="default_value">'image'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.encode_image">
<code class="sig-name descname">encode_image</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image_url</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.encode_image" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.encode_text">
<code class="sig-name descname">encode_text</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.encode_text" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.encoder_type">
<em class="property">property </em><code class="sig-name descname">encoder_type</code><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.encoder_type" title="Permalink to this definition">¶</a></dt>
<dd><p>The encoder type ensures it uses either the ‘encode’ or ‘encode_question’/’encode_answer’
Currently supported encoder types:</p>
<blockquote>
<div><p>Question-Answer
Text-Image
Encoder</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.image_resize">
<code class="sig-name descname">image_resize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image_array</span></em>, <em class="sig-param"><span class="n">width</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">height</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">rescale</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">resize_mode</span><span class="o">=</span><span class="default_value">'symmetric'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.image_resize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.is_url_working">
<em class="property">static </em><code class="sig-name descname">is_url_working</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">url</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.is_url_working" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.read">
<code class="sig-name descname">read</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image_url</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.read" title="Permalink to this definition">¶</a></dt>
<dd><p>An method to read images.
:param image: An image link/bytes/io Bytesio data format.
:param as_gray: read in the image as black and white</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.request_api_key">
<code class="sig-name descname">request_api_key</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">username</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">email</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">referral</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.request_api_key" title="Permalink to this definition">¶</a></dt>
<dd><p>Requesting an API key.</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.retrieve_all_documents">
<code class="sig-name descname">retrieve_all_documents</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.retrieve_all_documents" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieve all documents.</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.retrieve_documents">
<code class="sig-name descname">retrieve_documents</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_of_documents</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.retrieve_documents" title="Permalink to this definition">¶</a></dt>
<dd><p>Get all the documents in our package.</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.rgb_weights">
<em class="property">property </em><code class="sig-name descname">rgb_weights</code><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.rgb_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Get RGB weights for grayscaling.</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.search">
<code class="sig-name descname">search</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">item</span><span class="p">:</span> <span class="n">Any</span></em>, <em class="sig-param"><span class="n">num_results</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">10</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.search" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple search with Vector AI</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.show_image">
<code class="sig-name descname">show_image</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span></em>, <em class="sig-param"><span class="n">cmap</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">is_grayscale</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.show_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Show an image once it is read.
Arg:</p>
<blockquote>
<div><p>sample: Image that is read (numpy array)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.test_word">
<em class="property">property </em><code class="sig-name descname">test_word</code><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.test_word" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.to_grayscale">
<code class="sig-name descname">to_grayscale</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span></em>, <em class="sig-param"><span class="n">rgb_weights</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>list<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.to_grayscale" title="Permalink to this definition">¶</a></dt>
<dd><p>Converting an image from RGB to Grayscale</p>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.urls">
<em class="property">property </em><code class="sig-name descname">urls</code><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.urls" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.validate_model_url">
<em class="property">classmethod </em><code class="sig-name descname">validate_model_url</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_url</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">list_of_urls</span><span class="p">:</span> <span class="n">List<span class="p">[</span>str<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.validate_model_url" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate the model url belongs in the list of urls. This is to help
users to avoid mis-spelling the name of the model.</p>
<p># TODO:
Improve model URL validation to not include final number in URl string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_url</strong> – The URl of the the model in question</p></li>
<li><p><strong>list_of_urls</strong> – The list of URLS for the model in question</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.vector_length">
<em class="property">property </em><code class="sig-name descname">vector_length</code><a class="headerlink" href="#vectorhub.bi_encoders.text_image.torch.clip2vec.Clip2Vec.vector_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the vector length of the model.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-vectorhub.bi_encoders.text_image.torch">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-vectorhub.bi_encoders.text_image.torch" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Vector AI.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>